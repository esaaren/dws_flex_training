# Copyright 2025 Google Inc. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

apiVersion: v1
kind: Service
metadata:
  name: headless-svc
spec:
  clusterIP: None # clusterIP must be None to create a headless service
  selector:
    job-name: torch-job # must match Job name
  ports:
  - protocol: TCP
    port: 29400
    targetPort: 29400
---
apiVersion: batch/v1
kind: Job
metadata:
  name: torch-job
  labels:
    app: torch-job
spec:
  parallelism: 4
  completions: 4
  backoffLimit: 0
  completionMode: Indexed
  template:
    metadata:
      annotations:
        gke-gcsfuse/volumes: "true"
        gke-gcsfuse/cpu-limit: "0"
        gke-gcsfuse/memory-limit: "0"
        gke-gcsfuse/ephemeral-storage-limit: "0"
        autoscaling.x-k8s.io/consume-provisioning-request: provreq-gpu
        autoscaling.x-k8s.io/provisioning-class-name: "queued-provisioning.gke.io"
        networking.gke.io/default-interface: 'eth0'
        networking.gke.io/interfaces: |
          [
            {"interfaceName":"eth0","network":"default"},
            {"interfaceName":"eth1","network":"gvnic-1"},
            {"interfaceName":"eth2","network":"rdma-0"},
            {"interfaceName":"eth3","network":"rdma-1"},
            {"interfaceName":"eth4","network":"rdma-2"},
            {"interfaceName":"eth5","network":"rdma-3"},
            {"interfaceName":"eth6","network":"rdma-4"},
            {"interfaceName":"eth7","network":"rdma-5"},
            {"interfaceName":"eth8","network":"rdma-6"},
            {"interfaceName":"eth9","network":"rdma-7"}
          ]
      labels:
        app: torch-job
    spec:
      serviceAccountName: erik-ksa
      #hostNetwork: false # Could cause issues with DNS resolution 
      subdomain: headless-svc
      restartPolicy: OnFailure
      #setHostnameAsFQDN: true
      containers:
        - name: job
          image: us-central1-docker.pkg.dev/PROJECT/erik-torch-images/torch-ultra-job:latest
          command: [ "sh" ]
          #command: [ "sleep" ]
          args: [ "./torch_dist_launch.sh" ]
          #args: [ "1000" ]
          ports:
          - containerPort: 29400
            protocol: TCP
          env:
            # Required 
            - name: LD_LIBRARY_PATH
              value: /usr/local/nvidia/lib64
            # Distributed torch job settings 
            - name: PORT
              value: "29400"
            - name: WORLD_SIZE
              value: "32"
            - name: NODES
              value: "4"
            - name: PROC_PER_NODE
              value: "8"
            - name: JOB_ID
              value: "123"
            - name: MASTER_ENDPOINT
              value: "torch-job-0.headless-svc:29400"
            - name: PYTORCH_SCRIPT_NAME
              value: "fsdp.py" # Update the script you want to run in here 
            # Data settings 
            - name: DATA_PATH
              value: '/data/training_data'
            - name: CHECKPOINT_PATH
              value: '/data/checkpoints'
            - name: DATASET_NAME
              value: "dair-ai/emotion"
            - name: DATA_SPLIT_TRAIN
              value: 'train'
            - name: DATA_SPLIT_EVAL
              value: 'validation'
            - name: DATA_SPLIT_TEST
              value: 'test'
            - name: DATA_SUBSET
              value: 'split'
            # Other settings 
            - name: TEST_AFTER_TRAINING
              value: 'True'
            - name: BATCH_LOG_INTERVAL
              value: "100"
            # Tokenizer settings 
            - name: SEQUENCE_LENGTH
              value: "316"
            - name: TOKENIZER_BATCH_SIZE
              value: "10000"
            - name: TOKENIZER_NUM_PROC
              value: "100"
            # Model settings 
            - name: MODEL_NAME
              value: "meta-llama/Llama-3.1-8B"
            - name: BATCH_SIZE
              value: "32"
            - name: EPOCHS
              value: "30"
            - name: WARMUP
              value: "0.1"
            - name: LEARNING_RATE
              value: "0.00002"
            - name: WEIGHT_DECAY
              value: "0.01"
            - name: GRAD_ACC_STEPS
              value: "1"
            - name: GRAD_CHECKPOINTING_ENABLE
              value: "False"
            # PEFT settings 
            - name: USE_PEFT
              value: "False"
            - name: PEFT_R
              value: "16"
            - name: PEFT_ALPHA
              value: "32"
            - name: PEFT_DROPOUT
              value: "0.05"
            # Checkpointing 
            - name: CHECKPOINT_EPOCHS
              value: "5"
            - name: RELOAD_CHECKPOINT
              value: "None" # Should be the epoch value e.g "1" or "None"
            # Hugging face home 
            - name: HF_HOME
              value: "/data"
            # NCCL timeout 
            - name: NCCL_TIMEOUT
              value: "120"
            # Hugging face token
            - name: HUGGING_FACE_HUB_TOKEN
              valueFrom:
                secretKeyRef:
                  name: hf-secret
                  key: hf_api_token
            - name: NCCL_DEBUG # NCCL debug setting
              value: "ERROR"
            - name: NCCL_DEBUG_SUBSYS # NCCL debug setting 
              value: "INIT,NET,ENV,COLL,GRAPH"
            # NCCL settings found in: /usr/local/gib/scripts/set_nccl_env.sh
            - name: NCCL_NET
              value: "gIB"
            - name: NCCL_CROSS_NIC
              value: "0"
            - name: NCCL_NET_GDR_LEVEL
              value: "PIX"
            - name: NCCL_P2P_NET_CHUNKSIZE
              value: "131072"
            - name: NCCL_P2P_PCI_CHUNKSIZE
              value: "131072"
            - name: NCCL_P2P_NVL_CHUNKSIZE
              value: "524288"
            - name: NCCL_NVLS_CHUNKSIZE
              value: "524288"
            - name: NCCL_IB_GID_INDEX
              value: "3"
            - name: NCCL_IB_ADAPTIVE_ROUTING
              value: "1"
            - name: NCCL_IB_QPS_PER_CONNECTION
              value: "4"
            - name: NCCL_IB_TC
              value: "52"
            - name: NCCL_IB_FIFO_TC
              value: "84"
            - name: NCCL_TUNER_CONFIG_PATH # NOTE: This is hardcoded based on your last export line
              value: "/usr/local/gib/configs/tuner_config_a3u.txtpb" # /usr/local/gib/configs/tuner_config_a4.txtpb for a4 
          securityContext:
            privileged: true
          volumeMounts:
            - name: library-dir-host
              mountPath: /usr/local/nvidia
            - name: gib
              mountPath: /usr/local/gib
            - name: shared-memory
              mountPath: /dev/shm
            - name: gcs-fuse-csi-ephemeral
              mountPath: /data
          resources:
            limits:
              nvidia.com/gpu: 8
      volumes:
        - name: library-dir-host
          hostPath:
            path: /home/kubernetes/bin/nvidia
        - name: gib
          hostPath:
            path: /home/kubernetes/bin/gib
        - name: shared-memory
          emptyDir:
            medium: "Memory"
            sizeLimit: 250Gi
        - name: gke-gcsfuse-cache
          emptyDir:
            medium: Memory
        - name: gcs-fuse-csi-ephemeral
          csi:
            driver: gcsfuse.csi.storage.gke.io
            volumeAttributes:
              bucketName: erik-torch-training
              mountOptions: "implicit-dirs,file-cache:enable-parallel-downloads:true,file-cache:parallel-downloads-per-file:100,file-cache:max-parallel-downloads:-1,file-cache:download-chunk-size-mb:10,file-cache:max-size-mb:-1"
        